import numpy as np
import cv2 as cv
import argparse
import os


def calc_coords(bb):
    '''
    The method used to evaluate coordinates of corners of the bounding box.
    Input: tuple (x, y, w, h), where:
    x - "x" coordinates of the top left corner
    y - "y" coordinates of the top left corner
    w - width of the bounding box
    h - the height of the bounding box
    Output: dictionary coordinates contain names of the values as keys and
    numerical values as values
    '''
    xmin = bb[0]
    xmax = bb[0] + bb[2] - 1.0
    ymin = bb[1]
    ymax = bb[1] + bb[3] - 1.0
    cx = bb[0] + (bb[2] + 1.0) / 2
    cy = bb[1] + (bb[3] + 1.0) / 2
    coords = {'xmin': xmin, 'xmax': xmax, 'ymin': ymin, 'ymax': ymax,
              'cx': cx, 'cy': cy}
    return coords


def get_iou(new, gt):
    '''
    During the calculation of intersection over union, we are checking
    numerical value of area_of_overlap, because if it is equal to 0,
    we have no intersection.
    Lists, generated by 'calc_coords', are used as input for these methods.

    Respectively:
    new[0],gt[0] -> xmin, new[1],gt[1] -> xmax, new[2],gt[2] -> ymin
    new[3],gt[3] -> ymax, new[4],gt[4] -> cx, new[5],gt[5] -> cy
    '''
    dx = max(0, min(new[1], gt[1]) - max(new[0], gt[0]))
    dy = max(0, min(new[3], gt[3]) - max(new[2], gt[2]))
    area_of_overlap = dx * dy
    if area_of_overlap != 0:
        area_of_union = (new[1] - new[0]) * (new[3] - new[2]) + (
            gt[1] - gt[0]) * (gt[3] - gt[2]) - area_of_overlap
        iou = area_of_overlap / area_of_union
    else:
        iou = 0
    return iou


def get_pr(new, gt):
    '''
    In calculations of precision and normalized precision are used thresholds
    from original TrackingNet paper: for metric calculation TrackingNet using
    lists of thresholds, but here we use only one numerical value of the
    threshold for each metric
    Lists, generated by 'calc_coords', are used as input for these methods.

    Respectively:
    new[0],gt[0] -> xmin, new[1],gt[1] -> xmax, new[2],gt[2] -> ymin
    new[3],gt[3] -> ymax, new[4],gt[4] -> cx, new[5],gt[5] -> cy
    '''
    precision = np.sqrt((new[4] - gt[4]) ** 2 + (new[5] - gt[5]) ** 2)
    if precision > 20.0:
        pr_value = 0.0
    else:
        pr_value = 1.0
    return pr_value


def get_norm_pr(new, gt, gt_bb_w, gt_bb_h):
    '''
    In calculations of precision and normalized precision are used thresholds
    from original TrackingNet paper: for metric calculation TrackingNet using
    lists of thresholds, but here we use only one numerical value of the
    threshold for each metric
    Lists, generated by 'calc_coords', are used as input for these methods.

    Respectively:
    new[0],gt[0] -> xmin, new[1],gt[1] -> xmax, new[2],gt[2] -> ymin
    new[3],gt[3] -> ymax, new[4],gt[4] -> cx, new[5],gt[5] -> cy
    '''
    normalized_precision = np.sqrt(((new[4] - gt[4]) / gt_bb_w) ** 2 + (
            (new[5] - gt[5]) / gt_bb_h) ** 2)
    if normalized_precision > 0.1:
        norm_pr_value = 0.0
    else:
        norm_pr_value = 1.0
    return norm_pr_value


def init_tracker(tracker_name):
    '''
    Method used for initializing of trackers by creating it
    via cv.TrackerX_create().
    Input: string with tracker name.
    Output: dictionary 'config'
    Dictionary 'config' contains trackers names
    as keys and tuple with call method and number of frames for
    reinitialization as values
    '''
    config = {"Boosting": (cv.TrackerBoosting_create(), 500),
              "MIL": (cv.TrackerMIL_create(), 1000),
              "KCF": (cv.TrackerKCF_create(), 250),
              "MedianFlow": (cv.TrackerMedianFlow_create(), 500),
              "GOTURN": (cv.TrackerGOTURN_create(), 250),
              "MOSSE": (cv.TrackerMOSSE_create(), 250),
              "CSRT": (cv.TrackerCSRT_create(), 250)}
    return config[tracker_name]


def main():
    parser = argparse.ArgumentParser(
        description="Run LaSOT-based benchmark for visual object trackers")
    # As a default argument used name of
    # original dataset folder
    parser.add_argument("--path_to_dataset", type=str,
                        default="LaSOTTesting", help="Full path to LaSOT")
    parser.add_argument("--visualization", action='store_true',
                        help="Showing process of tracking")
    args = parser.parse_args()

    # Creating list with names of videos via reading names from txt file
    video_names = os.path.join(args.path_to_dataset, "testing_set.txt")
    with open(video_names, 'rt') as f:
        list_of_videos = f.read().rstrip('\n').split('\n')
    trackers = [
        'Boosting', 'MIL', 'KCF', 'MedianFlow', 'GOTURN', 'MOSSE', 'CSRT']

    list_iou = []
    list_pr = []
    list_n_pr = []

    # Loop for every tracker
    for tracker_name in trackers:

        print("Tracker name: ", tracker_name)

        # Loop for every video
        for video_name in list_of_videos:

            tracker, frames_for_reinit = init_tracker(tracker_name)
            init_once = False

            print("\tVideo name: " + str(video_name))

            # Open specific video and read ground truth for it
            gt_file = open(os.path.join(args.path_to_dataset, video_name,
                           "groundtruth.txt"), "r")
            gt_bb = gt_file.readline().replace("\n", "").split(",")
            init_bb = gt_bb
            init_bb = tuple([float(b) for b in init_bb])

            # Creating blob from image sequence
            video_sequence = sorted(os.listdir(os.path.join(
                args.path_to_dataset, video_name, "img")))

            # Variables for saving sum of every metric for every frame and
            # every video respectively
            sum_iou = 0
            sum_pr = 0
            sum_norm_pr = 0
            iou_values = 0
            pr_values = 0
            norm_pr_values = 0
            frame_counter = len(video_sequence)

            # For every frame in video
            for number_of_the_frame, image in enumerate(video_sequence):
                frame = cv.imread(os.path.join(
                    args.path_to_dataset, video_name, "img", image))
                for i in range(len(gt_bb)):
                    gt_bb[i] = float(gt_bb[i])
                gt_bb = tuple(gt_bb)
                # frame = cv.imread(image)

                # Condition of tracker`s re-initialization
                if ((number_of_the_frame + 1) % frames_for_reinit == 0) and (
                        number_of_the_frame != 0):

                    tracker, frames_for_reinit = init_tracker(tracker_name)
                    init_once = False
                    init_bb = gt_bb

                if not init_once:
                    init_state = tracker.init(frame, init_bb)
                    init_once = True
                init_state, new_bb = tracker.update(frame)

                # Check for presence of object on the frame
                # If no object on frame, we reduce number of
                # accounted for evaluation frames
                if gt_bb != (0, 0, 0, 0):
                    # Calculation of coordinates of corners and centers
                    # from [x, y, w, h] bounding boxes

                    new_coords = list(calc_coords(new_bb).values())
                    gt_coords = list(calc_coords(gt_bb).values())

                    if args.visualization:
                        cv.rectangle(frame, (int(new_coords[0]), int(
                                     new_coords[2])), (int(new_coords[1]),
                                     int(new_coords[3])), (200, 0, 0))
                        cv.imshow("Tracking", frame)
                        cv.waitKey(1)

                    sum_iou += get_iou(new_coords, gt_coords)
                    sum_pr += get_pr(new_coords, gt_coords)
                    sum_norm_pr += get_norm_pr(
                        new_coords, gt_coords, gt_bb[2], gt_bb[3])
                else:
                    frame_counter -= 1

                # Setting as ground truth bounding box from next frame
                gt_bb = gt_file.readline().replace("\n", "").split(",")

            # Calculating mean arithmetic value for specific video
            iou_values += sum_iou / frame_counter
            pr_values += sum_pr / frame_counter
            norm_pr_values += sum_norm_pr / frame_counter

        list_iou.append(np.mean(iou_values))
        list_pr.append(np.mean(pr_values))
        list_n_pr.append(np.mean(norm_pr_values))
    titles = ["Names:", "IoU:", "Precision:", "N.Precision:"]
    data = [titles] + list(zip(trackers, list_iou, list_pr, list_n_pr))
    for number, for_tracker in enumerate(data):
        line = '|'.join(str(x).ljust(20) for x in for_tracker)
        print(line)
        if i == 0:
            print('-' * len(line))


if __name__ == '__main__':
    main()
