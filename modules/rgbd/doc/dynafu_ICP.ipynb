{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DynaFu ICP Math\n",
    "## Differentiating and Linearising Rt matrices\n",
    "\n",
    "In dynafu, the warp function looks like the following for each node $i$:\n",
    "\n",
    "\n",
    "$\n",
    "\\begin{equation*}\n",
    "f_i(x_i, V_g) = T_{x_i} * V_g = R(x_i) * V_g + t(x_i)\n",
    "\\end{equation*}\n",
    "$\n",
    "\n",
    "where ${x_i}$ are the transformation parameters for node $i$ and the rotation is performed around the corresponding node (and not a global reference)\n",
    "\n",
    "For linearising a transform around the parameters $\\mathbf{x}$, we need to find the derivative\n",
    "\n",
    "$\n",
    "\\begin{equation*}\n",
    "\\displaystyle\n",
    "\\frac{\\partial f_i(\\mathbf{x} \\circ \\epsilon,   V_g)}{\\partial \\epsilon} |_{\\epsilon = 0}\n",
    "\\end{equation*}\n",
    "$\n",
    "\n",
    "We calculate this as follows:\n",
    "\n",
    "$\n",
    "\\begin{equation*}\n",
    "f_i(\\mathbf{x} \\circ \\epsilon, V_g) = f_i(\\epsilon, V) = T_{inc} * V\n",
    "\\end{equation*}\n",
    "$ where $V = f_i(\\mathbf{x}, V_g)$ and $T_{inc}$ is the infinitesimal transform with parameters $\\epsilon$\n",
    "\n",
    "According to Lie algebra, each Rt matrix can be represented as $A = e^\\xi$ where $\\xi$ are the transform parameters. Therefore,\n",
    "\n",
    "\n",
    "$\n",
    "\\begin{equation*}\n",
    "f_i(\\mathbf{x}, V_g) = e^\\xi V\n",
    "\\end{equation*}\n",
    "$\n",
    "\n",
    "Therefore,\n",
    "\n",
    "$\n",
    "\\begin{equation*}\n",
    "\\displaystyle\n",
    "\\frac{\\partial f_i(\\mathbf{x} \\circ \\xi,   V_g)}{\\partial \\xi} |_{\\xi = 0} =\n",
    "\\frac{\\partial e^\\xi V}{\\partial \\xi} |_{\\xi=0} = \n",
    "\\begin{pmatrix} -[V]_{\\times} & I_{3x3} \\end{pmatrix}_{3 \\times 6}\n",
    "\\end{equation*}\n",
    "$\n",
    "\n",
    "Let us denote $\\begin{pmatrix} -[V]_{\\times} & I_{3x3} \\end{pmatrix}$ as $G(V)$ from now on.\n",
    "\n",
    "This result is mentioned in [this manifold optimisation tutorial](http://ingmec.ual.es/~jlblanco/papers/jlblanco2010geometry3D_techrep.pdf) (equation 10.23).\n",
    "\n",
    "With this result, we can now linearise our transformation around $\\mathbf{x}$:\n",
    "\n",
    "$\n",
    "\\begin{equation*}\n",
    "f_i(x_i, V_g) = G(V) * \\epsilon + V\n",
    "\\end{equation*}\n",
    "$\n",
    "\n",
    "\n",
    "I suppose the following is an equivalent excerpt from the dynafu paper (Section about efficient optimisation) that mentions this way of calculating derivatives:\n",
    "> We formulate compositional updates $\\hat x$ through the exponential map with a per-node twist $ξ_i ∈ se(3)$, requiring 6 variables per node transform, and perform linearisation  around $ξ_i=  0$. \n",
    "\n",
    "As a side note, the derivative $\\large \\frac{\\partial e^\\xi}{\\partial \\xi}|_{\\xi=0}$ is called the tangent (esentially the derivative) to the SE(3) manifold (the space in which Rt matrix $T_{inc}$ exists) at identity ($\\xi = 0$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating Warp Field Parameters\n",
    "The total energy to be minimised is \n",
    "\n",
    "$\n",
    "E = E_{data} + \\lambda E_{reg}\n",
    "$\n",
    "\n",
    "#### Data term rearrangement \n",
    "$\n",
    "\\displaystyle\n",
    "E_{data} = \\sum_{u \\in \\Omega} \\rho_{Tukey}(N_g^T (V_g - T_u^{-1}\\cdot V_c))\n",
    "$\n",
    "\n",
    "The quadcopter paper tells us that the following expression has the same minimiser, so we can use this instead:\n",
    "\n",
    "$\n",
    "\\displaystyle\n",
    "E_{data} = \\sum_{u \\in \\Omega} w_{Tukey}(r_u) \\cdot (r_u)^2\n",
    "$\n",
    "\n",
    "where $w_{Tukey}(x) = \\rho'(x)/x$ which behaves like a constant term and $r_u = N_g^T (V_g - T_u^{-1}\\cdot V_c)$\n",
    "\n",
    "#### Regularisation term rearrangement\n",
    "$\n",
    "\\begin{equation}\n",
    "\\displaystyle\n",
    "E_{reg} = \\sum_{i = 0}^n \\sum_{j \\in \\varepsilon(i)} \\alpha_{ij} \\rho_{Huber} (T_{i}V_g^j - T_{j}V_g^j)\n",
    "\\end{equation}\n",
    "$\n",
    "\n",
    "This needs to be changed to the form of weighted least squares to be useful. So incorporate the same rearrangement as the data term and sum over edges instead:\n",
    "\n",
    "$\n",
    "\\begin{equation}\n",
    "\\displaystyle\n",
    "E_{reg} = \\sum_{e \\in E} w_{Huber}(r_e) (r_e)^2\n",
    "\\end{equation}\n",
    "$\n",
    "\n",
    "Here $E$ is the set of the directed edges in the regularisation graph between all nodes from current level and the next coarser level. And $w_{Huber}(x) = \\alpha_x \\rho'(x)/x$\n",
    "\n",
    "#### Obtaining normal equation\n",
    "\n",
    "Therefore to solve an iteration, we equate the derivative with 0\n",
    "\n",
    "$\n",
    "\\begin{equation*}\n",
    "\\large\n",
    "\\frac{\\partial E_{data}}{\\partial \\xi} + \\lambda \\frac{\\partial E_{reg}}{\\partial \\xi} = 0\n",
    "\\end{equation*}\n",
    "$\n",
    "\n",
    "which gives us\n",
    "\n",
    "$\n",
    "\\begin{equation*}\n",
    "J_d^T W_d(r_d + J_d\\mathbf{\\hat x}) + \\lambda J_r^T W_r (r_r + J_r\\mathbf{\\hat x}) = 0\n",
    "\\end{equation*}\n",
    "$\n",
    "\n",
    "$\n",
    "(J_d^T W_d J_d + \\lambda J_r^T W_r J_r)\\mathbf{\\hat x} = -(J_d^T W_d r_d + \\lambda J_r^T W_r r_r)\n",
    "$\n",
    "\n",
    "Here $W_d$ and $W_r$ are the weight matrices as described in quadcopter paper. However for $W_r, \\alpha$ is also incorporated in this matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Data Term Jacobian ($J_d$) \n",
    "\n",
    "Each entry in $J_d$ is as follows for node paramter $x_j$ for each node $j$:\n",
    "\n",
    "$\n",
    "\\begin{equation*}\n",
    "\\displaystyle\n",
    "(J_d)_{uj} = \\frac{\\partial r_u}{\\partial x_j} = -N_g^T \\frac{\\partial T_u^{-1} V_c}{\\partial x_j}\n",
    "\\end{equation*}\n",
    "$\n",
    "\n",
    "\n",
    "From chain rule\n",
    "\n",
    "$\n",
    "\\begin{equation*}\n",
    "\\displaystyle\n",
    "\\frac{\\partial T_u^{-1} V_c}{\\partial x_j} = \\frac{\\partial T_u^{-1} V_c}{\\partial T_u} \\frac{\\partial T_u}{\\partial x_j}\n",
    "\\end{equation*}\n",
    "$\n",
    "\n",
    "\n",
    "Equation 7.20 in the manifold optimisation tutorial tells us how to calculate the first term \n",
    "\n",
    "$\n",
    "\\begin{equation*}\n",
    "\\displaystyle\n",
    "\\frac{\\partial T_u^{-1} V_c}{\\partial T_u} = \n",
    "\\begin{pmatrix}\n",
    "I_3 \\otimes (V_c - t_u)^T & R_u\n",
    "\\end{pmatrix}\n",
    "\\end{equation*}\n",
    "$\n",
    "\n",
    "where $\\otimes$ denotes the [Kronecker product](https://en.wikipedia.org/wiki/Kronecker_product) and $R_u, t_u$ are the rotation matrix and translation vector of $T_u$ respectively\n",
    "\n",
    "$\n",
    "\\begin{equation*}\n",
    "\\displaystyle\n",
    "\\frac{\\partial T_u}{\\partial x_j} = \\frac{w_j}{\\sum_{k \\in N(V_u)} w_k} \\frac{\\partial T_j}{\\partial x_j}\n",
    "\\end{equation*}\n",
    "$\n",
    "\n",
    "As per equation 10.15 of the tutorial,\n",
    "\n",
    "$\n",
    "\\begin{equation*}\n",
    "\\displaystyle\n",
    "\\frac{\\partial T_j}{\\partial x_j} = \n",
    "\\begin{pmatrix}\n",
    "0_{3\\times3} & - [R_j^{c1}]_\\times \\\\\n",
    "0_{3\\times3} & - [R_j^{c2}]_\\times \\\\\n",
    "0_{3\\times3} & - [R_j^{c3}]_\\times \\\\\n",
    "I_{3\\times3} & - [t_j]_\\times\n",
    "\\end{pmatrix}\n",
    "\\end{equation*}\n",
    "$\n",
    "\n",
    "where $R_j^{c1}$ is the first column of the rotation matrix of node $j$, $R_j^{c2}$ is the second column and so on.\n",
    "\n",
    "Combining these results, we get\n",
    "\n",
    "$\n",
    "\\begin{equation*}\n",
    "\\displaystyle\n",
    "\\frac{\\partial T_u^{-1} V_c}{\\partial x_j} =\n",
    "\\frac{w_j}{\\sum_{k \\in N(V_u)} w_k}\n",
    "\\begin{pmatrix}\n",
    "I_3 \\otimes (V_c - t_u)^T & R_u\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "0_{3\\times3} & - [R_j^{c1}]_\\times \\\\\n",
    "0_{3\\times3} & - [R_j^{c2}]_\\times \\\\\n",
    "0_{3\\times3} & - [R_j^{c3}]_\\times \\\\\n",
    "I_{3\\times3} & - [t_j]_\\times\n",
    "\\end{pmatrix}\n",
    "\\end{equation*}\n",
    "$\n",
    "\n",
    "$\n",
    "=\n",
    "\\frac{w_j}{\\sum_{k \\in N(V_u)} w_k}\n",
    "\\left(\n",
    "\\begin{pmatrix}\n",
    "R_u & R_j^T [V_c]_\\times\n",
    "\\end{pmatrix}\n",
    "- \\left(\n",
    "\\begin{array}{c|c}\n",
    "0_{3\\times3} & R_j^T[t_u]_\\times - R_u^T[t_j]_\\times\n",
    "\\end{array}\n",
    "\\right)\n",
    "\\right)\n",
    "$\n",
    "\n",
    "It may be noted that this result is obtained through a variation of equation 10.25 of the manifold optimisation tutorial.\n",
    "\n",
    "Therefore,\n",
    "$\n",
    "\\begin{equation*}\n",
    "(J_d)_{uj} = \\frac{w_j}{\\sum_{k \\in N(V_u)} w_k}\n",
    "-\\left(\n",
    "N_g^T \\begin{pmatrix}\n",
    "R_u & R_j^T [V_c]_\\times\n",
    "\\end{pmatrix}\n",
    "- \n",
    "N_g^T \\left(\n",
    "\\begin{array}{c|c}\n",
    "0_{3\\times3} & R_j^T[t_u]_\\times - R_u^T[t_j]_\\times\n",
    "\\end{array}\n",
    "\\right)\n",
    "\\right)\n",
    "\\end{equation*}\n",
    "$\n",
    "\n",
    "We can rewrite \n",
    "$\n",
    "N_g^T \\begin{pmatrix}\n",
    "R_u & R_j^T [V_c]_\\times\n",
    "\\end{pmatrix}\n",
    "$ as\n",
    "\n",
    "$\n",
    "\\begin{equation*}\n",
    "\\left(\n",
    "\\begin{pmatrix}\n",
    "R_u^T \\\\\n",
    "(R_j^T [V_c]_\\times)^T\n",
    "\\end{pmatrix}\n",
    "N_g\n",
    "\\right)^T\n",
    "\\end{equation*}\n",
    "$$\n",
    "=\n",
    "\\begin{equation*}\n",
    "\\begin{pmatrix}\n",
    "R_u^T N_g \\\\\n",
    "(R_j^T [V_c]_\\times)^T N_g\n",
    "\\end{pmatrix}^T\n",
    "\\end{equation*}\n",
    "$$\n",
    "=\n",
    "\\begin{equation*}\n",
    "\\begin{pmatrix}\n",
    "(R_u^T N_g)^T &\n",
    "N_g^T (R_j^T [V_c]_\\times)\n",
    "\\end{pmatrix}\n",
    "\\end{equation*}\n",
    "$\n",
    "\n",
    "We know that all rotation matrices are skew symmetric, which means we can replace $R^T$ by $-R$ everywhere.\n",
    "So now we have:\n",
    "\n",
    "$\n",
    "\\begin{equation}\n",
    "(J_d)_{uj} = \\frac{w_j}{\\sum_{k \\in N(V_u)} w_k}\n",
    "\\left(\n",
    "\\begin{pmatrix}\n",
    "(R_u N_g)^T &\n",
    "N_g^T (R_j [V_c]_\\times)\n",
    "\\end{pmatrix}\n",
    "-\n",
    "N_g^T \\left(\n",
    "\\begin{array}{c|c}\n",
    "0_{3\\times3} & R_j[t_u]_\\times - R_u[t_j]_\\times\n",
    "\\end{array}\n",
    "\\right)\n",
    "\\right)\n",
    "\\end{equation}\n",
    "$\n",
    "\n",
    "But this expression is only valid if $j \\in N(V_u)$, because otherwise $frac{\\partial T_u}{\\partial x_j} = 0$ in the chain rule, making the entire term 0.\n",
    "\n",
    "The final expression of the data term Jacobian is:\n",
    "\n",
    "$\n",
    "\\begin{equation}\n",
    "(J_d)_{uj} = \n",
    "\\begin{cases}\n",
    "\\frac{w_j}{\\sum_{k \\in N(V_u)} w_k}\n",
    "\\left(\n",
    "\\begin{pmatrix}\n",
    "(R_u N_g)^T &\n",
    "N_g^T (R_j [V_c]_\\times)\n",
    "\\end{pmatrix}\n",
    "-\n",
    "N_g^T \\left(\n",
    "\\begin{array}{c|c}\n",
    "0_{3\\times3} & R_j[t_u]_\\times - R_u[t_j]_\\times\n",
    "\\end{array}\n",
    "\\right)\n",
    "\\right) & \\text{if  } j \\in N(V_u) \\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Regularisation Term Jacobian ($J_r$)\n",
    "\n",
    "Each row in $J_r$ corresponds to derivative to summand for each edge $e$ and column $k$ corresponds to node $k$ with respect to which the derivative is calculated.\n",
    "\n",
    "$\n",
    "\\begin{equation*}\n",
    "\\displaystyle\n",
    "(J_r)_{ek} = \n",
    "\\frac{\\partial ( T_iV_g^j - T_jV_g^j)}{\\partial x_k}\n",
    "=\n",
    "\\begin{cases}\n",
    "\\begin{pmatrix} -[T_iV_g^j] & I_{3x3} \\end{pmatrix} & \\text {if   }  i = k \\\\\n",
    "0 & \\text {otherwise}\n",
    "\\end{cases}\n",
    "\\end{equation*}\n",
    "$\n",
    "\n",
    "Please note that $T_j$ is constant in all the cases since the corresponding node lies in the next level and there is no $k$ such that $k=j$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
