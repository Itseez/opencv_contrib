{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DynaFu ICP Math\n",
    "## Differentiating and Linearising Rt matrices\n",
    "\n",
    "In dynafu, the warp function looks like the following for each node $i$:\n",
    "\n",
    "\n",
    "$\n",
    "\\begin{equation*}\n",
    "f_i(x_i, V_g) = T_{x_i} * V_g = R(x_i) * V_g + t(x_i)\n",
    "\\end{equation*}\n",
    "$\n",
    "\n",
    "where ${x_i}$ are the transformation parameters for node $i$ and the rotation is performed around the corresponding node (and not a global reference)\n",
    "\n",
    "For linearising a transform around the parameters $\\mathbf{x}$, we need to find the derivative\n",
    "\n",
    "$\n",
    "\\begin{equation*}\n",
    "\\displaystyle\n",
    "\\frac{\\partial f_i(\\mathbf{x} \\circ \\epsilon,   V_g)}{\\partial \\epsilon} |_{\\epsilon = 0}\n",
    "\\end{equation*}\n",
    "$\n",
    "\n",
    "We calculate this as follows:\n",
    "\n",
    "$\n",
    "\\begin{equation*}\n",
    "f_i(\\mathbf{x} \\circ \\epsilon, V_g) = f_i(\\epsilon, V) = T_{inc} * V\n",
    "\\end{equation*}\n",
    "$ where $V = f_i(\\mathbf{x}, V_g)$ and $T_{inc}$ is the infinitesimal transform with parameters $\\epsilon$\n",
    "\n",
    "According to Lie algebra, each Rt matrix can be represented as $A = e^\\xi$ where $\\xi$ are the transform parameters. Therefore,\n",
    "\n",
    "\n",
    "$\n",
    "\\begin{equation*}\n",
    "f_i(\\mathbf{x}, V_g) = e^\\xi V\n",
    "\\end{equation*}\n",
    "$\n",
    "\n",
    "Therefore,\n",
    "\n",
    "$\n",
    "\\begin{equation*}\n",
    "\\displaystyle\n",
    "\\frac{\\partial f_i(\\mathbf{x} \\circ \\xi,   V_g)}{\\partial \\xi} |_{\\xi = 0} =\n",
    "\\frac{\\partial e^\\xi V}{\\partial \\xi} |_{\\xi=0} = \n",
    "\\begin{pmatrix} -[V]_{\\times} & I_{3x3} \\end{pmatrix}_{3 \\times 6}\n",
    "\\end{equation*}\n",
    "$\n",
    "\n",
    "Let us denote $\\begin{pmatrix} -[V]_{\\times} & I_{3x3} \\end{pmatrix}$ as $G(V)$ from now on.\n",
    "\n",
    "This result is mentioned in [this tutorial](http://ingmec.ual.es/~jlblanco/papers/jlblanco2010geometry3D_techrep.pdf) (equation 10.23).\n",
    "\n",
    "With this result, we can now linearise our transformation around $\\mathbf{x}$:\n",
    "\n",
    "$\n",
    "\\begin{equation*}\n",
    "f_i(x_i, V_g) = G(V) * \\epsilon + V\n",
    "\\end{equation*}\n",
    "$\n",
    "\n",
    "\n",
    "I suppose the following is an equivalent excerpt from the dynafu paper (Section about efficient optimisation) that mentions this way of calculating derivatives:\n",
    "> We formulate compositional updates $\\hat x$ through the exponential map with a per-node twist $ξ_i ∈ se(3)$, requiring 6 variables per node transform, and perform linearisation  around $ξ_i=  0$. \n",
    "\n",
    "As a side note, the derivative $\\large \\frac{\\partial e^\\xi}{\\partial \\xi}|_{\\xi=0}$ is called the tangent (esentially the derivative) to the SE(3) manifold (the space in which Rt matrix $T_{inc}$ exists) at identity ($\\xi = 0$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating Warp Field Parameters\n",
    "The total energy to be minimised is \n",
    "\n",
    "$\n",
    "E = E_{data} + \\lambda E_{reg}\n",
    "$\n",
    "\n",
    "#### Data term rearrangement \n",
    "$\n",
    "\\displaystyle\n",
    "E_{data} = \\sum_{u \\in \\Omega} \\rho_{Tukey}(N_g^T (V_g - T_u^{-1}\\cdot V_c))\n",
    "$\n",
    "\n",
    "The quadcopter paper tells us that the following expression has the same minimiser, so we can use this instead:\n",
    "\n",
    "$\n",
    "\\displaystyle\n",
    "E_{data} = \\sum_{u \\in \\Omega} w_{Tukey}(r_u) \\cdot (r_u)^2\n",
    "$\n",
    "\n",
    "where $w_{Tukey}(x) = \\rho'(x)/x$ which behaves like a constant term and $r_u = N_g^T (V_g - T_u^{-1}\\cdot V_c)$\n",
    "\n",
    "#### Regularisation term rearrangement\n",
    "$\n",
    "\\begin{equation}\n",
    "\\displaystyle\n",
    "E_{reg} = \\sum_{i = 0}^n \\sum_{j \\in \\varepsilon(i)} \\alpha_{ij} \\rho_{Huber} (T_{i}V_g^j - T_{j}V_g^j)\n",
    "\\end{equation}\n",
    "$\n",
    "\n",
    "This needs to be changed to the form of weighted least squares to be useful. So incorporate the same rearrangement as the data term and sum over edges instead:\n",
    "\n",
    "$\n",
    "\\begin{equation}\n",
    "\\displaystyle\n",
    "E_{reg} = \\sum_{e \\in E} w_{Huber}(r_e) (r_e)^2\n",
    "\\end{equation}\n",
    "$\n",
    "\n",
    "Here $E$ is the set of the directed edges in the regularisation graph between all nodes from current level and the next coarser level. And $w_{Huber}(x) = \\alpha_x \\rho'(x)/x$\n",
    "\n",
    "#### Obtaining normal equation\n",
    "\n",
    "Therefore to solve an iteration, we equate the derivative with 0\n",
    "\n",
    "$\n",
    "\\begin{equation*}\n",
    "\\large\n",
    "\\frac{\\partial E_{data}}{\\partial \\xi} + \\lambda \\frac{\\partial E_{reg}}{\\partial \\xi} = 0\n",
    "\\end{equation*}\n",
    "$\n",
    "\n",
    "which gives us\n",
    "\n",
    "$\n",
    "\\begin{equation*}\n",
    "J_d^T W_d(r_d + J_d\\mathbf{\\hat x}) + \\lambda J_r^T W_r (r_r + J_r\\mathbf{\\hat x}) = 0\n",
    "\\end{equation*}\n",
    "$\n",
    "\n",
    "$\n",
    "(J_d^T W_d J_d + \\lambda J_r^T W_r J_r)\\mathbf{\\hat x} = -(J_d^T W_d r_d + \\lambda J_r^T W_r r_r)\n",
    "$\n",
    "\n",
    "Here $W_d$ and $W_r$ are the weight matrices as described in quadcopter paper. However for $W_r, \\alpha$ is also incorporated in this matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Data Term Jacobian ($J_d$) \n",
    "\n",
    "Each entry in J_d is as follows for node paramter x_j for each node j:\n",
    "\n",
    "$\n",
    "\\begin{equation*}\n",
    "\\displaystyle\n",
    "(J_d)_{uj} = \\frac{\\partial r_u}{\\partial x_j} = -N_g^T \\frac{\\partial T_u^{-1} V_c}{\\partial x_j}\n",
    "\\end{equation*}\n",
    "$\n",
    "\n",
    "Since each T_u is calculated as a weighted sum,\n",
    "\n",
    "$\n",
    "\\begin{equation*}\n",
    "\\displaystyle\n",
    "T_u^{-1}V_c = \\begin{pmatrix} \\frac{\\sum_{k \\in N(V_u)} w_k T_k}{\\sum w_k} \\end{pmatrix}^{-1} V_c\n",
    "\\end{equation*}\n",
    "$\n",
    "\n",
    "**Note: Although we perform the weighted averaging of transformed points instead of the Rt matrices themselves, the math remains unchanged**\n",
    "\n",
    "Since only the transformation of node $j$ is dependent on $x_i$, derivatives of all other transforms in the average is 0. The derivative of the term with $T_j$ is $\\begin{pmatrix} -[T_jV_c]_{\\times} & I_{3x3} \\end{pmatrix}$\n",
    "\n",
    "$\n",
    "\\begin{equation*}\n",
    "\\frac{\\partial T_u^{-1} V_c}{\\partial x_j} = \n",
    "\\begin{cases} \n",
    "\\frac{\\partial \\frac{w_j T_j^{-1} V_c}{\\sum w_k}}{\\partial x_j} & \\text {if} j \\in N(V_u) \\\\\n",
    "0 & \\text {otherwise}\n",
    "\\end{cases}\n",
    "\\end{equation*}\n",
    "$\n",
    "\n",
    "Equation 10.25 from the tutorial tells us that:\n",
    "\n",
    "$\n",
    "\\begin{equation*}\n",
    "\\frac{\\partial T_j^{-1} V_c}{\\partial x_j} = \n",
    "\\begin{pmatrix}\n",
    "(-[V_c]_\\times R_j) ^ T & R_j\n",
    "\\end{pmatrix} =\n",
    "\\begin{pmatrix}\n",
    "(R_j \\times V_c)^T & R_j\n",
    "\\end{pmatrix}\n",
    "\\end{equation*}\n",
    "$\n",
    "\n",
    "where $R_j$ is the rotation matrix of $T_j$. Therefore, we now have\n",
    "\n",
    "$\n",
    "\\begin{equation*}\n",
    "\\frac{\\partial T_u^{-1} V_c}{\\partial x_j} = \n",
    "\\begin{cases} \n",
    "\\frac{w_j \\begin{pmatrix} (R_j \\times V_c)^T & R_j \\end{pmatrix}}{\\sum_{k \\in N(V_u)} w_k} & \\text {if} j \\in N(V_u) \\\\\n",
    "0 & \\text {otherwise}\n",
    "\\end{cases}\n",
    "\\end{equation*}\n",
    "$\n",
    "\n",
    "Putting this all together, we get\n",
    "\n",
    "$\n",
    "\\begin{equation*}\n",
    "\\displaystyle\n",
    "(J_d)_{uj} = \n",
    "\\frac{\\partial r_u}{\\partial x_j} =\n",
    "\\begin{cases}\n",
    "N_g^T \\frac{w_j \\begin{pmatrix} (R_j \\times V_c)^T & R_j \\end{pmatrix}}{\\sum_{k \\in N(V_u)} w_k} & \\text {if} j \\in N(V_u) \\\\\n",
    "0 & \\text {otherwise}\n",
    "\\end{cases}\n",
    "\\end{equation*}\n",
    "$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Regularisation Term Jacobian ($J_r$)\n",
    "\n",
    "Each row in $J_r$ corresponds to derivative to summand for each edge $e$ and column $k$ corresponds to node $k$ with respect to which the derivative is calculated.\n",
    "\n",
    "$\n",
    "\\begin{equation*}\n",
    "\\large\n",
    "(J_r)_{ek} = \n",
    "\\frac{\\partial ( T_iV_g^j - T_jV_g^j)}{\\partial x_k}\n",
    "=\n",
    "\\begin{cases}\n",
    "\\begin{pmatrix} -[T_iV_g^j] & I_{3x3} \\end{pmatrix} & \\text {if   }  i = k \\\\\n",
    "0 & \\text {otherwise}\n",
    "\\end{cases}\n",
    "\\end{equation*}\n",
    "$\n",
    "\n",
    "Please note that $T_j$ is constant in all the cases since the corresponding node lies in the next level and there is no $k$ such that $k=j$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
